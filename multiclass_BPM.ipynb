{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import edward as ed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import six\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from edward.models import Normal,Empirical,Bernoulli,Categorical\n",
    "from tensorflow.contrib import slim\n",
    "from tensorflow.contrib.keras.api.keras.layers import Dense\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import train_utils as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ed.set_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtype = 'bpm'\n",
    "iftype = 'VI'\n",
    "dataset = 'MNIST'\n",
    "zero_constraint = False\n",
    "test_logistic_regression = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "N = 20000 # number of training data points\n",
    "N_test = 5000 # number of testing data points\n",
    "\n",
    "noise_std = .01\n",
    "B = 100 # batch size during training\n",
    "\n",
    "if dataset == 'MNIST':\n",
    "    DATA_DIR = \"../data/mnist\"\n",
    "    IMG_DIR = \"img\"\n",
    "    mnist = input_data.read_data_sets(DATA_DIR)\n",
    "    X = mnist.train.images[:N]\n",
    "    Y = mnist.train.labels[:N]\n",
    "    X_test = mnist.test.images[:N_test]\n",
    "    Y_test = mnist.test.labels[:N_test]\n",
    "    M = X.shape[1]+1\n",
    "    H = 10\n",
    "    #normalise\n",
    "    X = (X - X.mean())/X.std()\n",
    "elif dataset == 'synthesis': \n",
    "    M = 2 # number of features\n",
    "    H = 2 # number of classes\n",
    "    \n",
    "    s_mean = 0.\n",
    "    s_std = 1.\n",
    "    d_mean = 0.\n",
    "    d_std = 3.\n",
    "    \n",
    "    Y,X = util.build_toy_dataset(mtype,N,M-1,H,s_std,s_mean,d_std)\n",
    "    Y_test,X_test = util.build_toy_dataset(mtype,N_test,M-1,H,s_std,s_mean,d_std)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression train accuracy:  0.9461\n",
      "Logistic regression test accuracy:  0.7998\n"
     ]
    }
   ],
   "source": [
    "if test_logistic_regression:\n",
    "    lgr = LogisticRegression(n_jobs=8,fit_intercept=True)\n",
    "    lgr.fit(X,Y)\n",
    "    print('Logistic regression train accuracy: ',sum(lgr.predict(X)==Y)/N)\n",
    "    print('Logistic regression test accuracy: ',sum(lgr.predict(X_test)==Y_test)/N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.hstack((X,np.ones((N,1))))\n",
    "X_test = np.hstack((X_test,np.ones((X_test.shape[0],1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 785)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.astype(np.float32)\n",
    "#Y = Y.astype(np.float32)\n",
    "\n",
    "x_ph = tf.placeholder(tf.float32, [B,M])\n",
    "y_ph = tf.placeholder(tf.int32,[B])\n",
    "y_ph_ohe = tf.placeholder(tf.float32,[B,H]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "if zero_constraint:\n",
    "    w = Normal(tf.zeros([H-1,M]),tf.ones([H-1,M]))\n",
    "    \n",
    "    if iftype == 'HMC':\n",
    "        qw = Empirical(params=tf.Variable(tf.random_normal([B,H-1,M])))\n",
    "    else:\n",
    "        qw = Normal(tf.Variable(tf.random_normal([H-1,M])), tf.nn.softplus(tf.Variable(tf.random_normal([H-1,M]))))\n",
    "\n",
    "    y = Categorical(tf.nn.softmax(Normal(tf.concat([tf.matmul(x_ph,tf.transpose(w)),tf.zeros([B,1])],axis=1), noise_std)))\n",
    "    y_test = tf.nn.softmax(tf.concat([tf.matmul(x_ph,tf.transpose(qw.loc)),tf.zeros([B,1])],axis=1))\n",
    "else:\n",
    "\n",
    "    w = Normal(tf.zeros([H,M]),tf.ones([H,M]))\n",
    "\n",
    "    if iftype == 'HMC':\n",
    "        qw = Empirical(params=tf.Variable(tf.random_normal([B,H,M])))\n",
    "    else:\n",
    "        qw = Normal(tf.Variable(tf.random_normal([H,M])), tf.nn.softplus(tf.Variable(tf.random_normal([H,M]))))\n",
    "\n",
    "    y = Categorical(tf.nn.softmax(Normal(tf.matmul(x_ph,tf.transpose(w)), noise_std)))\n",
    "    y_test = tf.nn.softmax(tf.matmul(x_ph,tf.transpose(qw.loc)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inference\n",
    "scaling = float(N) / B\n",
    "nprint = 1000\n",
    "niter = 20000\n",
    "\n",
    "if iftype == 'EP':\n",
    "    inference = ed.KLpq({w:qw},data={y:y_ph})\n",
    "elif iftype == 'VI':\n",
    "    inference = ed.KLqp({w:qw},data={y:y_ph})\n",
    "elif iftype == 'HMC':\n",
    "    inference = ed.HMC({w:qw},data={y:y_ph})\n",
    "else:\n",
    "    print('invalid inference type')\n",
    "    \n",
    "inference.initialize(n_iter=niter,n_print=nprint,scale={y:scaling})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = ed.get_session()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "    1/20000 [  0%]                                ETA: 5259s | Loss: 53990.281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_utils.py:14: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if labels!=None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " w mean:\n",
      "[[  2.67822266e-01  -1.51020789e+00  -1.17865455e+00 ...,  -1.84761047e-01\n",
      "   -6.00543320e-02   2.62241697e+00]\n",
      " [ -6.88719392e-01   3.66260767e-01  -7.26246953e-01 ...,  -2.00679526e-03\n",
      "    7.05349445e-03   2.45263249e-01]\n",
      " [  3.59947920e-01   2.20906568e+00  -1.11120105e+00 ...,   1.89409447e+00\n",
      "   -8.55887771e-01  -1.10888946e+00]\n",
      " ..., \n",
      " [  8.41239452e-01  -6.53325200e-01  -4.13533211e-01 ...,  -2.44671404e-02\n",
      "    3.94323897e+00   2.75328219e-01]\n",
      " [  1.64461064e+00   1.09980273e+00   1.27512217e-01 ...,   6.00731850e-01\n",
      "    7.01308250e-04  -5.82185626e-01]\n",
      " [  3.35248321e-01   1.60996556e-01  -1.01432458e-01 ...,   1.39070201e+00\n",
      "    7.07330346e-01  -3.94003719e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_utils.py:23: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if labels == None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1000/20000 [  5%] █                              ETA: 25s | Loss: 38683.613\n",
      " w mean:\n",
      "[[-1.21243393  0.17324366  0.60993636 ..., -2.18824697 -0.8407042\n",
      "   0.3460393 ]\n",
      " [ 0.46579108 -0.49815896 -0.10677464 ..., -1.54218745 -0.53067887\n",
      "  -0.29770374]\n",
      " [-1.38680172  0.67412698 -1.00517583 ...,  1.96893454 -0.54159641\n",
      "   1.56141317]\n",
      " ..., \n",
      " [ 1.39497411  1.95443225 -0.132515   ..., -1.60168505  1.98014581\n",
      "   2.77921438]\n",
      " [ 2.46722293  0.80048126 -1.03170204 ..., -0.34431851 -1.21401703\n",
      "   0.01540397]\n",
      " [ 0.23285615 -0.27904716 -0.12100218 ..., -0.4286074   0.18486455\n",
      "  -0.55285728]]\n",
      " 2000/20000 [ 10%] ███                            ETA: 22s | Loss: 35170.191\n",
      " w mean:\n",
      "[[ 1.1341182  -0.28098479  1.03415859 ..., -0.4112249  -0.51607668\n",
      "  -1.52690589]\n",
      " [ 0.42127228 -0.93755102 -0.26536256 ..., -0.81387937  0.54299688\n",
      "   1.36934638]\n",
      " [-1.10966778 -1.67036104  0.4514921  ..., -0.97145045 -0.32489905\n",
      "   0.09871459]\n",
      " ..., \n",
      " [-0.76343101 -1.23990417 -0.68970513 ..., -0.44924581  0.41307643\n",
      "   1.89784598]\n",
      " [-1.40039444 -0.85027075  1.70619571 ..., -0.977741    1.35724282\n",
      "  -1.41151941]\n",
      " [-0.53246766 -1.10330725  0.01095518 ..., -0.39498782 -0.85311586\n",
      "   0.30232382]]\n",
      " 3000/20000 [ 15%] ████                           ETA: 20s | Loss: 35063.312\n",
      " w mean:\n",
      "[[-0.04750074 -1.86321771 -0.70619541 ..., -0.10818183 -0.31203499\n",
      "   0.33910009]\n",
      " [ 0.06883794 -1.87681878 -2.43494034 ..., -1.61141944  1.72406185\n",
      "   1.12478304]\n",
      " [-0.07972801 -0.45794868  1.33242071 ...,  0.2134413   0.30576572\n",
      "   1.19588745]\n",
      " ..., \n",
      " [-0.23784216 -0.72841281 -0.07874258 ..., -0.64718562 -1.26411402\n",
      "  -0.28974688]\n",
      " [ 0.54574645  1.17752981  1.324651   ...,  1.50362945  0.10481764\n",
      "   0.29680187]\n",
      " [ 0.02770684 -2.05216694 -2.68639112 ..., -0.62652934  0.34416005\n",
      "  -1.76748776]]\n",
      " 4000/20000 [ 20%] ██████                         ETA: 18s | Loss: 34376.273\n",
      " w mean:\n",
      "[[ 0.7141335   0.0573194  -0.82774627 ..., -0.94385672  0.26402673\n",
      "  -1.41797912]\n",
      " [-0.34470257  0.52633989 -0.20848165 ..., -0.47870764 -0.26835582\n",
      "   0.25349793]\n",
      " [-0.75610542  0.63803381 -0.9186126  ..., -0.52767813 -0.29605752\n",
      "   0.49403083]\n",
      " ..., \n",
      " [ 0.83345455 -0.02153149  0.40597275 ...,  1.0120343  -0.38276625\n",
      "   0.85388744]\n",
      " [-1.88825417 -0.88951564  1.11525822 ...,  1.35095823  0.55751777\n",
      "  -1.40248775]\n",
      " [-0.80490768  0.88901109 -0.06470307 ..., -0.49397454  0.28294465\n",
      "   0.73675323]]\n",
      " 5000/20000 [ 25%] ███████                        ETA: 16s | Loss: 34803.398\n",
      " w mean:\n",
      "[[-1.32011497  0.19741055 -0.92355013 ...,  0.12974887 -1.11132395\n",
      "  -0.58588666]\n",
      " [-0.33468184 -0.42025328  1.74852586 ...,  0.28840801  2.1404891\n",
      "  -0.47901091]\n",
      " [-0.27909303 -1.72620595 -0.63461882 ..., -0.43542928 -0.20872021\n",
      "   0.39123452]\n",
      " ..., \n",
      " [ 1.29384649  0.92931151  1.70057094 ...,  0.86221862  0.86730468\n",
      "  -0.64968169]\n",
      " [ 1.074368   -0.60719186  0.27927303 ...,  1.85383642  1.98210239\n",
      "  -0.58374321]\n",
      " [ 1.1032629   0.20517531  1.34889781 ...,  1.36663985  0.1830726\n",
      "   0.22736457]]\n",
      " 6000/20000 [ 30%] █████████                      ETA: 15s | Loss: 34409.973\n",
      " w mean:\n",
      "[[ 0.24180044  1.18586516  1.21331716 ...,  0.40270293  0.0723144\n",
      "   0.00240475]\n",
      " [ 0.71007288  0.14785454 -0.78619659 ...,  0.93357497  0.91302729\n",
      "   0.29445374]\n",
      " [-0.43354067  0.29923242 -1.56415141 ..., -0.94956595  1.31755352\n",
      "  -0.39902592]\n",
      " ..., \n",
      " [-1.04559374 -1.77637255 -0.40211445 ..., -1.16427994 -0.27330816\n",
      "   0.56010985]\n",
      " [ 1.32244468 -1.17141509  0.98472726 ...,  0.6822471  -0.86636233\n",
      "  -1.91939497]\n",
      " [ 0.64007729 -0.90080124  1.32586908 ...,  0.21705773  0.03489074\n",
      "   0.55829275]]\n",
      " 7000/20000 [ 35%] ██████████                     ETA: 13s | Loss: 34106.703\n",
      " w mean:\n",
      "[[ 1.92047822  0.57544351  0.14539051 ..., -0.67909497 -0.71925741\n",
      "  -0.98221987]\n",
      " [ 0.10867395  1.40230513 -0.40440023 ..., -0.9205339   0.85664809\n",
      "   0.56682897]\n",
      " [-0.17777365  1.02728236  0.79194039 ...,  1.32217896 -0.04241192\n",
      "   0.93201256]\n",
      " ..., \n",
      " [ 0.2462718  -1.05822659 -1.27248979 ...,  0.49951741  0.21094519\n",
      "   1.7765944 ]\n",
      " [ 0.72475153  0.53609157  0.16845492 ...,  1.48235691 -0.17745811\n",
      "   0.50877118]\n",
      " [ 0.05251311  0.49694142  0.73249638 ...,  0.35052559  0.08109198\n",
      "   0.26619393]]\n",
      " 8000/20000 [ 40%] ████████████                   ETA: 12s | Loss: 34980.098\n",
      " w mean:\n",
      "[[ 2.70483041 -0.73749584 -0.6519025  ..., -1.12859654 -0.56112945\n",
      "   0.18607415]\n",
      " [ 1.85471678  0.83434457 -0.34605634 ..., -0.11651959  1.12158144\n",
      "  -0.16976276]\n",
      " [-0.08241583 -2.52791882 -0.7249254  ..., -0.18119711  0.69672877\n",
      "   0.58502799]\n",
      " ..., \n",
      " [ 0.454162   -0.97751969 -0.72353691 ...,  1.11337888  0.04824315\n",
      "   0.32541096]\n",
      " [ 0.28734067  0.01601937 -0.38403165 ...,  0.78631878  0.62597108\n",
      "  -0.24171796]\n",
      " [ 2.86837149 -0.54370403 -1.22527361 ...,  0.60669386  0.52498221\n",
      "  -0.47352862]]\n",
      " 9000/20000 [ 45%] █████████████                  ETA: 11s | Loss: 34769.980\n",
      " w mean:\n",
      "[[-1.8765614  -0.50551212 -0.41331506 ..., -1.53695679 -1.71682191\n",
      "   0.2081238 ]\n",
      " [ 0.90946239  0.31450343  0.08481744 ...,  0.2700735   0.12335162\n",
      "   2.2715404 ]\n",
      " [-0.22784536  0.45056844 -0.2682879  ..., -0.0037563   1.43628824\n",
      "   0.42459625]\n",
      " ..., \n",
      " [ 1.50179732  0.43412989 -0.75628012 ...,  0.00806724  1.67113185\n",
      "   0.75262535]\n",
      " [ 0.66223431 -1.47846353 -1.78568459 ...,  1.02523482  3.20336652\n",
      "   0.07061991]\n",
      " [ 0.06915033  0.80897468 -0.85614944 ...,  2.53166103 -0.56175637\n",
      "   0.49255151]]\n",
      "10000/20000 [ 50%] ███████████████                ETA: 10s | Loss: 33117.770\n",
      " w mean:\n",
      "[[ -7.53826559e-01   3.23852122e-01   8.55323792e-01 ...,  -5.97668648e-01\n",
      "   -1.39698255e+00  -5.20552218e-01]\n",
      " [  1.12199175e+00  -8.04094553e-01  -1.41080469e-03 ...,  -4.71981645e-01\n",
      "    1.68644047e+00  -2.21891299e-01]\n",
      " [ -5.98719954e-01  -4.48039174e-03  -4.70213830e-01 ...,  -8.74254882e-01\n",
      "    8.77424657e-01  -1.85046345e-01]\n",
      " ..., \n",
      " [  2.25618172e+00  -3.46854389e-01  -1.55234158e+00 ...,   4.05145288e-02\n",
      "   -4.68941897e-01   5.37855744e-01]\n",
      " [ -5.22475481e-01  -4.30143982e-01   9.90581989e-01 ...,   6.66502893e-01\n",
      "    6.93083942e-01   2.51728147e-01]\n",
      " [ -7.01447129e-01  -1.00856686e+00   2.26939535e+00 ...,  -5.86635292e-01\n",
      "    7.54575312e-01   1.13661647e+00]]\n",
      "11000/20000 [ 55%] ████████████████               ETA: 9s | Loss: 34087.078\n",
      " w mean:\n",
      "[[-0.0820321   0.07917894 -0.43936476 ...,  1.93014669 -0.61300868\n",
      "  -0.90146005]\n",
      " [ 0.35913759  0.10620513 -0.67079186 ..., -0.87020427  0.26129735\n",
      "   0.28419271]\n",
      " [ 1.64724851 -0.91485876 -1.64824772 ..., -1.60894966  1.3655256\n",
      "   0.48286194]\n",
      " ..., \n",
      " [ 1.1933794  -0.57110995 -1.54406285 ..., -0.07178441  0.48623735\n",
      "  -0.48739108]\n",
      " [-1.03563261  0.02136052  1.1630311  ..., -1.02250135 -0.30324867\n",
      "   0.25130731]\n",
      " [ 0.72947544  0.99901807 -1.00337017 ..., -1.24433696 -0.99575078\n",
      "   0.55350125]]\n",
      "12000/20000 [ 60%] ██████████████████             ETA: 8s | Loss: 33577.168\n",
      " w mean:\n",
      "[[-0.81223214  0.84697729 -1.70674765 ...,  0.07369325 -1.81223285\n",
      "  -0.26383963]\n",
      " [-0.31150794 -1.64320016  1.53471255 ...,  0.16455245 -1.5399549\n",
      "  -0.05722153]\n",
      " [ 0.04350765  0.07134828  1.08629274 ..., -0.02201646  0.44218588\n",
      "   0.09539846]\n",
      " ..., \n",
      " [-0.29643962  1.70517457 -1.59692466 ...,  0.29041323  0.04391693\n",
      "   1.55165482]\n",
      " [ 0.05174302  0.62626195 -0.61010748 ...,  2.01171637 -0.6079849\n",
      "  -0.54997706]\n",
      " [-1.34019578  0.93685251  0.76005048 ...,  1.45544243 -0.4961403\n",
      "   0.02496395]]\n",
      "13000/20000 [ 65%] ███████████████████            ETA: 7s | Loss: 33794.535\n",
      " w mean:\n",
      "[[ 1.10806692 -1.29032588  0.34798592 ...,  1.18963301 -0.99683636\n",
      "  -0.87325305]\n",
      " [ 0.28941169 -1.16888237  1.31108093 ...,  1.02768183  0.50632972\n",
      "   0.50097519]\n",
      " [-0.39247766 -0.73235446  0.26596913 ...,  0.60829926  0.51397967\n",
      "  -0.84218091]\n",
      " ..., \n",
      " [-1.01129663  1.3688519  -0.70395565 ...,  1.17194474  0.59899974\n",
      "  -0.24114686]\n",
      " [ 0.19344038  0.74064755 -0.08675706 ...,  0.22065961 -0.11714439\n",
      "   0.16963777]\n",
      " [ 2.55723476  0.40600923 -1.04822934 ...,  0.27377817  0.52109385\n",
      "   0.48048428]]\n",
      "14000/20000 [ 70%] █████████████████████          ETA: 6s | Loss: 33984.727\n",
      " w mean:\n",
      "[[-0.42611215 -0.58798593 -0.62673289 ..., -1.08580947  0.74053687\n",
      "   0.02085298]\n",
      " [-1.46845174  1.8697809   0.89042509 ..., -1.24913144  0.98060852\n",
      "  -0.19794956]\n",
      " [ 0.31268352  1.23960698 -0.83932877 ..., -0.9151448   1.2433331\n",
      "  -0.78482372]\n",
      " ..., \n",
      " [ 2.49309826  0.94445068  0.9618032  ..., -0.42713994 -0.14021048\n",
      "   0.8902719 ]\n",
      " [ 0.77334297 -0.55348068  1.7706548  ...,  0.85907251 -1.48940444\n",
      "  -0.05706985]\n",
      " [ 0.35847959  0.16561581  1.84012187 ..., -1.34462655 -0.34155062\n",
      "  -0.89546406]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/20000 [ 75%] ██████████████████████         ETA: 5s | Loss: 35091.758\n",
      " w mean:\n",
      "[[ 0.14566132 -0.65791881  0.03277641 ...,  0.76480663  0.18264417\n",
      "   0.38647068]\n",
      " [ 0.89844805  1.20096481 -0.7505306  ...,  0.47410506  0.99964255\n",
      "   0.42704001]\n",
      " [-1.54161704 -0.15599906 -1.72597766 ..., -0.43599355 -0.42263824\n",
      "   0.11891308]\n",
      " ..., \n",
      " [ 0.5641728  -1.35753286 -0.55483788 ...,  1.16626787  0.01191663\n",
      "  -0.12132458]\n",
      " [ 1.20249116  0.33333489 -0.50969553 ...,  1.28476775 -0.47734132\n",
      "  -1.79122746]\n",
      " [ 0.69181776  0.07064035 -0.66236871 ..., -0.43659431  1.93525434\n",
      "  -0.66263449]]\n",
      "16000/20000 [ 80%] ████████████████████████       ETA: 4s | Loss: 33927.852\n",
      " w mean:\n",
      "[[-1.14550257  2.46165872  0.77798581 ..., -0.45457432  1.3382113\n",
      "  -0.04069033]\n",
      " [ 0.90337908 -0.34321791 -1.23148751 ...,  0.89406478 -0.99558806\n",
      "  -0.19531184]\n",
      " [-0.80012143 -1.04712629 -0.27539328 ...,  1.93954539  1.97658396\n",
      "  -1.19280612]\n",
      " ..., \n",
      " [ 0.2288304  -0.75238866  0.59764934 ..., -0.07961151 -0.68861341\n",
      "   0.48962134]\n",
      " [ 0.98260885 -0.58537883  1.59305453 ...,  0.39769885  0.50789005\n",
      "  -0.3609122 ]\n",
      " [ 0.71537095 -1.77212608  0.78238511 ...,  1.04768682  0.0826222\n",
      "  -0.58655441]]\n",
      "17000/20000 [ 85%] █████████████████████████      ETA: 3s | Loss: 33907.074\n",
      " w mean:\n",
      "[[-0.54285634  0.70161372 -0.52695352 ..., -0.86147803 -0.4501265\n",
      "  -0.67925459]\n",
      " [-0.27025175  0.47782701  1.16188669 ..., -1.27045512  1.07489288\n",
      "  -1.14148962]\n",
      " [-1.55382168  0.40853068  0.15926248 ...,  0.55364698 -0.04490418\n",
      "   0.09866238]\n",
      " ..., \n",
      " [-1.59260976 -0.98813254  0.35426089 ..., -1.80828679 -1.62151349\n",
      "   0.94607413]\n",
      " [-1.00151002 -0.2652542  -0.48128766 ...,  0.09436601  0.68407255\n",
      "  -0.4727149 ]\n",
      " [ 0.59903955  1.45768023 -1.08381486 ...,  0.76642764  0.21418682\n",
      "   0.94948077]]\n",
      "18000/20000 [ 90%] ███████████████████████████    ETA: 2s | Loss: 33703.828\n",
      " w mean:\n",
      "[[ 0.47333595 -1.08504856  0.68455088 ...,  1.03077197 -1.62863064\n",
      "  -0.92812043]\n",
      " [-0.2407037   0.98263097  0.69891816 ..., -0.39401197  0.4402146\n",
      "  -0.30758753]\n",
      " [-2.45860267  0.66790956  0.71573955 ..., -0.06740647  0.50060236\n",
      "   0.36007237]\n",
      " ..., \n",
      " [-1.09950614  0.44862676 -0.21251903 ..., -0.86070442  1.22446489\n",
      "   0.2090074 ]\n",
      " [ 1.19026387 -0.84632277  0.11062929 ..., -2.3629384   1.28677022\n",
      "   0.26772991]\n",
      " [ 0.81548822  0.47675455 -0.26748282 ..., -0.48030868  0.19005425\n",
      "   0.39522484]]\n",
      "19000/20000 [ 95%] ████████████████████████████   ETA: 1s | Loss: 33539.945\n",
      " w mean:\n",
      "[[ 0.02662216 -1.13322294 -1.66965532 ...,  0.26410106  0.4339557\n",
      "  -0.72124958]\n",
      " [-0.64437044 -0.66550118 -1.81843781 ...,  0.37551066  0.9637897\n",
      "  -0.82300234]\n",
      " [-1.05184162  0.6187526   0.42535529 ...,  0.39522466  0.43915221\n",
      "  -0.40075547]\n",
      " ..., \n",
      " [ 2.2244277  -1.21455479 -1.06575882 ..., -0.05966302  1.00876534\n",
      "   0.51392686]\n",
      " [ 0.79209203 -0.97121859 -0.67281657 ...,  0.20590419  1.60292602\n",
      "   2.91075802]\n",
      " [-0.27925977  0.82400727  0.26454276 ..., -0.97607279 -0.66337997\n",
      "  -0.06929477]]\n",
      "20000/20000 [100%] ██████████████████████████████ Elapsed: 20s | Loss: 33618.645\n"
     ]
    }
   ],
   "source": [
    "ii = 0\n",
    "sess = ed.get_session()\n",
    "for t in range(niter):\n",
    "    x_batch,y_batch,ii = util.get_next_batch(X,B,ii,Y)\n",
    "  \n",
    "    info_dict = inference.update(feed_dict={x_ph:x_batch,y_ph:y_batch})\n",
    "    inference.print_progress(info_dict)\n",
    "    \n",
    "    if t % nprint == 0:\n",
    "        print('\\n w mean:')\n",
    "        print(sess.run(qw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8066\n"
     ]
    }
   ],
   "source": [
    "ii = 0\n",
    "acu = 0\n",
    "\n",
    "for i in range(int(np.floor(N_test/B))):\n",
    "    x_batch,y_batch,ii = util.get_next_batch(X_test,B,ii,Y_test)\n",
    "    y_test_batch = sess.run(y_test,feed_dict={x_ph:x_batch,y_ph:y_batch})\n",
    "    acu += sum(np.argmax(y_test_batch,axis=1)==y_batch)\n",
    "print('Test accuracy: ', acu*1./N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9057\n"
     ]
    }
   ],
   "source": [
    "ii = 0\n",
    "acu = 0\n",
    "\n",
    "for i in range(int(np.floor(N/B))):\n",
    "    x_batch,y_batch,ii = util.get_next_batch(X,B,ii,Y)\n",
    "    y_test_batch = sess.run(y_test,feed_dict={x_ph:x_batch,y_ph:y_batch})\n",
    "    acu += sum(np.argmax(y_test_batch,axis=1)==y_batch)\n",
    "print('Train accuracy: ', acu*1./N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
