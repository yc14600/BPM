{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import edward as ed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import six\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from edward.models import Normal,Empirical,Bernoulli,Categorical\n",
    "from tensorflow.contrib import slim\n",
    "from tensorflow.contrib.keras.api.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import train_utils as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtype = 'bpm'\n",
    "iftype = 'VI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 10000  # number of data points\n",
    "M = 3 # number of features\n",
    "H = 3 # number of classes\n",
    "B = 64 # batch size during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_mean = 0.\n",
    "s_std = 1.\n",
    "\n",
    "d_mean = 0.\n",
    "d_std = 3.\n",
    "\n",
    "noise_std = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y,X = util.build_toy_dataset(mtype,N,M-1,H,s_std,s_mean,d_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy:  0.9737\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(X,Y)\n",
    "print('Logistic regression accuracy: ',sum(lgr.predict(X)==Y)/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((X,np.ones((N,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.astype(np.float32)\n",
    "#Y = Y.astype(np.float32)\n",
    "\n",
    "x_ph = tf.placeholder(tf.float32, [B,M])\n",
    "y_ph = tf.placeholder(tf.int32,[B])\n",
    "y_ph_ohe = tf.placeholder(tf.float32,[B,H]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "w = Normal(tf.zeros([H-1,M]),tf.ones([H-1,M]))\n",
    "    \n",
    "if iftype == 'HMC':\n",
    "    qw = Empirical(params=tf.Variable(tf.random_normal([B,H-1,M])))\n",
    "else:\n",
    "    qw = Normal(tf.Variable(tf.random_normal([H-1,M])), tf.nn.softplus(tf.Variable(tf.random_normal([H-1,M]))))\n",
    "\n",
    "#y = Categorical(tf.nn.softmax(Normal(tf.matmul(x_ph,tf.transpose(w)), noise_std)))\n",
    "y = Categorical(tf.nn.softmax(Normal(tf.concat([tf.matmul(x_ph,tf.transpose(w)),tf.zeros([B,1])],axis=1), noise_std)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_1:0' shape=(64, 3) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([tf.matmul(x_ph,tf.transpose(w)),tf.zeros([B,1])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Normal_1/sample/Reshape:0' shape=(2, 3) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack(qw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "scaling = float(N) / B\n",
    "nprint = 1000\n",
    "niter = 20000\n",
    "\n",
    "if iftype == 'EP':\n",
    "    inference = ed.KLpq({w:qw},data={y:y_ph})\n",
    "elif iftype == 'VI':\n",
    "    inference = ed.KLqp({w:qw},data={y:y_ph})\n",
    "elif iftype == 'HMC':\n",
    "    inference = ed.HMC({w:qw},data={y:y_ph})\n",
    "else:\n",
    "    print('invalid inference type')\n",
    "    \n",
    "inference.initialize(n_iter=niter,n_print=nprint,scale={y:scaling})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = ed.get_session()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "    1/20000 [  0%]                                ETA: 5266s | Loss: 10028.760"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_utils.py:14: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if labels!=None:\n",
      "train_utils.py:23: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if labels == None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " w mean:\n",
      "[[ 1.19152808 -1.8171078   0.92566633]\n",
      " [-0.89208293  1.22391331  0.94041562]]\n",
      " 1000/20000 [  5%] █                              ETA: 14s | Loss: 6268.221 \n",
      " w mean:\n",
      "[[ -3.16143012  -3.23294711  15.08413315]\n",
      " [ -1.00944471  -1.14759254   9.37395287]]\n",
      " 2000/20000 [ 10%] ███                            ETA: 11s | Loss: 6375.683\n",
      " w mean:\n",
      "[[ -3.3198359   -3.41533899  17.08827019]\n",
      " [ -1.23479724  -1.3176918   10.87611771]]\n",
      " 3000/20000 [ 15%] ████                           ETA: 9s | Loss: 6550.994\n",
      " w mean:\n",
      "[[ -3.35916471  -3.49550176  17.69033051]\n",
      " [ -1.27370107  -1.37511158  11.25664806]]\n",
      " 4000/20000 [ 20%] ██████                         ETA: 8s | Loss: 6176.009\n",
      " w mean:\n",
      "[[ -3.454566    -3.58475184  17.65071297]\n",
      " [ -1.23226678  -1.34309614  11.4538784 ]]\n",
      " 5000/20000 [ 25%] ███████                        ETA: 8s | Loss: 6398.906\n",
      " w mean:\n",
      "[[ -3.57357526  -3.79705477  17.7316227 ]\n",
      " [ -1.22293544  -1.30811608  11.29979897]]\n",
      " 6000/20000 [ 30%] █████████                      ETA: 7s | Loss: 6268.377\n",
      " w mean:\n",
      "[[ -3.47053981  -3.55915117  17.72690392]\n",
      " [ -1.25484133  -1.35894287  11.51728439]]\n",
      " 7000/20000 [ 35%] ██████████                     ETA: 6s | Loss: 6329.319\n",
      " w mean:\n",
      "[[ -3.59080839  -3.6529839   17.53107262]\n",
      " [ -1.248824    -1.39143825  11.46280861]]\n",
      " 8000/20000 [ 40%] ████████████                   ETA: 6s | Loss: 6547.513\n",
      " w mean:\n",
      "[[ -3.46887207  -3.65744376  17.88996506]\n",
      " [ -1.23716235  -1.34627151  11.43602467]]\n",
      " 9000/20000 [ 45%] █████████████                  ETA: 5s | Loss: 6174.089\n",
      " w mean:\n",
      "[[ -3.61487412  -3.58216524  17.6046772 ]\n",
      " [ -1.22530389  -1.35993791  11.45800209]]\n",
      "10000/20000 [ 50%] ███████████████                ETA: 5s | Loss: 6408.366\n",
      " w mean:\n",
      "[[ -3.57679534  -3.67283988  17.94488525]\n",
      " [ -1.25326121  -1.34231341  11.47276974]]\n",
      "11000/20000 [ 55%] ████████████████               ETA: 4s | Loss: 6236.951\n",
      " w mean:\n",
      "[[ -3.57098293  -3.46728182  17.61707115]\n",
      " [ -1.24426568  -1.34508753  11.39361477]]\n",
      "12000/20000 [ 60%] ██████████████████             ETA: 4s | Loss: 6328.297\n",
      " w mean:\n",
      "[[ -3.33082771  -3.48881769  17.99572563]\n",
      " [ -1.23449564  -1.32852733  11.30466843]]\n",
      "13000/20000 [ 65%] ███████████████████            ETA: 3s | Loss: 6562.910\n",
      " w mean:\n",
      "[[ -3.55255294  -3.55940866  17.8156147 ]\n",
      " [ -1.2793591   -1.36899877  11.51020813]]\n",
      "14000/20000 [ 70%] █████████████████████          ETA: 2s | Loss: 6177.000\n",
      " w mean:\n",
      "[[ -3.46539211  -3.56744385  17.80075455]\n",
      " [ -1.25239265  -1.32507396  11.47247982]]\n",
      "15000/20000 [ 75%] ██████████████████████         ETA: 2s | Loss: 6402.174\n",
      " w mean:\n",
      "[[ -3.51301813  -3.53942323  17.79706955]\n",
      " [ -1.23903489  -1.36503243  11.56363964]]\n",
      "16000/20000 [ 80%] ████████████████████████       ETA: 1s | Loss: 6256.195\n",
      " w mean:\n",
      "[[ -3.44348645  -3.56882596  17.78783798]\n",
      " [ -1.26486075  -1.33297169  11.39189243]]\n",
      "17000/20000 [ 85%] █████████████████████████      ETA: 1s | Loss: 6372.229\n",
      " w mean:\n",
      "[[ -3.62253618  -3.70629501  17.63373947]\n",
      " [ -1.24394536  -1.35607731  11.32546043]]\n",
      "18000/20000 [ 90%] ███████████████████████████    ETA: 0s | Loss: 6551.275\n",
      " w mean:\n",
      "[[ -3.46306467  -3.56721616  17.70022774]\n",
      " [ -1.25040209  -1.34841967  11.52924061]]\n",
      "19000/20000 [ 95%] ████████████████████████████   ETA: 0s | Loss: 6173.105\n",
      " w mean:\n",
      "[[ -3.52237916  -3.45671082  17.6346817 ]\n",
      " [ -1.28451979  -1.33041894  11.4754858 ]]\n",
      "20000/20000 [100%] ██████████████████████████████ Elapsed: 9s | Loss: 6392.024\n"
     ]
    }
   ],
   "source": [
    "ii = 0\n",
    "sess = ed.get_session()\n",
    "for t in range(niter):\n",
    "    x_batch,y_batch,ii = util.get_next_batch(X,B,ii,Y)\n",
    "  \n",
    "    info_dict = inference.update(feed_dict={x_ph:x_batch,y_ph:y_batch})\n",
    "    inference.print_progress(info_dict)\n",
    "    \n",
    "    if t % nprint == 0:\n",
    "        print('\\n w mean:')\n",
    "        print(sess.run(qw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9814\n"
     ]
    }
   ],
   "source": [
    "ii = 0\n",
    "acu = 0\n",
    "y_test = tf.nn.softmax(tf.concat([tf.matmul(x_ph,tf.transpose(qw.loc)),tf.zeros([B,1])],axis=1))\n",
    "for i in range(int(np.ceil(N/B))):\n",
    "    x_batch,y_batch,ii = util.get_next_batch(X,B,ii,Y)\n",
    "    y_test_batch = sess.run(y_test,feed_dict={x_ph:x_batch,y_ph:y_batch})\n",
    "    acu += sum(np.argmax(y_test_batch,axis=1)==y_batch)\n",
    "print(acu*1./N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 0, 1, 0, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 0, 0, 2, 1, 0,\n",
       "       2, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 1, 0, 0, 2, 1, 2,\n",
       "       2, 2, 1, 2, 2, 2, 0, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test_batch,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 0, 1, 0, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 0, 0, 2, 1, 0,\n",
       "       2, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 2, 1, 1, 2, 1, 1, 0, 0, 2, 1, 2,\n",
       "       2, 2, 1, 2, 2, 2, 0, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
